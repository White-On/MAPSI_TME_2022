{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPSI semaine 5 : Indépendances conditionnelles et réseaux bayésiens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice : Indépendances conditionnelles et réseaux bayésiens\n",
    "Dans ce TME, l'objectif est d'apprendre des réseaux bayésiens à partir de bases de données. Hormis la base asia, un exemple jouet relativement petit qui vous permettra de mettre au point les différents algorithmes du TME, et car, les autres bases correspondront à des distributions de probabilité de tailles raisonnables : \n",
    "\n",
    "|  nom de la base  |            provenance           | nombre d'evenements elementaires |\n",
    "|:----------------:|:-------------------------------:|:--------------------------------:|\n",
    "|       asia       |          BN repository          |                $256     $          |\n",
    "|       alarm      |          BN repository          |              $10^{16}   $               |\n",
    "|       adult      | UCI machine learning repository |              $10^{12}   $          |\n",
    "|        car       | UCI machine learning repository |               $6912     $          |\n",
    "| agaricus-lepiota | UCI machine learning repository |              $10^{16}   $        |\n",
    "\n",
    "\n",
    "Apprendre un réseau bayésien consiste à apprendre sa structure graphique ainsi que les paramètres de ses distributions de probabilité conditionnelles. Pour réaliser la deuxième tâche, il suffit d'estimer les paramètres de chaque distribution conditionnelle par maximum de vraisemblance, comme vous l'avez fait dans le TME 3. Ici, nous nous focaliserons donc plutôt sur l'apprentissage de structure. Celle-ci reflétant des indépendances conditionnelles entre variables aléatoires, vous devrez exploiter des tests d'indépendance du χ2 afin d'obtenir des structures graphiques les moins denses possibles (en termes de nombres d'arcs). Ainsi, alarm représente une distribution jointe de plus de 1016 événements élémentaires mais, quand cette distribution est décomposée grâce au graphe ci-dessous (les noeuds représentant les variables aléatoires), elle peut être décrite (sans perte d'informations) à l'aide de seulement 752 paramètres. Comme nous l'avons vu en cours, cette représentation permet également d'effectuer très rapidement des calculs probabilistes.\n",
    "\n",
    "![Image ](tme5_alarm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Lecture des données\n",
    "\n",
    "Dans le code ci-dessous, la fonction `read_csv : string -> (string np.array, int np.2D-array, dico{string -> int} np.array)` vous permettra de lire les données des bases sur lesquelles vous allez travailler, et de les organiser sous une forme adéquate. Par exemple, une base de données est un fichier de la forme : \n",
    "\n",
    "```\n",
    " X_0,X_1,X_2,X_3\n",
    " haut,gauche,petit,bas\n",
    " bas,droite,grand,gauche\n",
    " bas,gauche,moyen,bas\n",
    "```\n",
    "\n",
    "\n",
    "Dans cette base, nous avons 4 variables aléatoires nommées X_0, X_1, X_2, et X_3, et 3 enregistrements qui représentent des instanciations (observées) de ces 4 variables. Ainsi, X_0 a pour valeurs haut, bas et bas, X_1 a pour valeurs gauche, droite, gauche, etc.\n",
    "\n",
    "La fonction `read_csv` prend en argument le nom d'un fichier CSV contenant une base de données et renvoie un triplet composé de :\n",
    "\n",
    "\n",
    "\n",
    "- 1 tableau numpy de strings contenant les noms des variables aléatoires. Par exemple, pour la base ci-dessus, ce tableau correspond à: \n",
    "```python\n",
    " n.array (['X_0', 'X_1', 'X_2', 'X_3'])\n",
    "```\n",
    "\n",
    "- un tableau numpy 2D contenant les données du fichier CSV encodées sous forme numérique (les valeurs des variables aléatoires sont transformées en nombres entiers): chaque ligne de ce tableau représente les intanciations d'une variable aléatoire et chaque colonne représente un enregistrement de la base de données, c'est-à-dire une instanciation/observation de toutes les variables aléatoires. Pour la base ci-dessus, nous obtiendrions le tableau ci-dessous (la signification des nombres est indiquée dans le dictionnaire précisé plus bas): \n",
    "```python\n",
    " np.array ( [ [0, 1, 1],   # instanciations de la variable X_0\n",
    "              [0, 1, 0],    # instanciations de la variable X_1\n",
    "              [0, 1, 2],    # instanciations de la variable X_2\n",
    "              [0, 1, 0]] )  # instanciations de la variable X_3\n",
    "```\n",
    "\n",
    "Ainsi, les valeurs observées de la première variable aléatoire X_0 correspondent à la première ligne du tableau (0, 1 et 1). La première colonne correspond à une observation de toutes les variables (X_0=0,X_1=0,X_2=0,X_3=0). C'est essentiellement sur ce tableau numpy que vous travaillerez dans ce TME. \n",
    "\n",
    "\n",
    "- un tableau numpy de dictionnaires faisant la correspondance, pour chaque variable aléatoire, entre l'encodage numérique du tableau 2D ci-dessus et les données du fichier CSV (le 1er dictionnaire correspond à la variable de la 1ère colonne du CSV, le 2ème dictionnaire à celle de la 2ème colonne, etc.). Ainsi, le dictionnaire est égal à : \n",
    "\n",
    "```python\n",
    "np.array( [ {'haut': 0, 'bas': 1},                  # encodage variable X_0\n",
    "             {'gauche': 0, 'droite': 1},            # encodage variable X_1\n",
    "             {'petit': 0, 'grand': 1, 'moyen': 2 }, # encodage variable X_2\n",
    "             {'bas': 0, 'gauche': 1} ] )            # encodage variable X_3\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "On peut ainsi reconstituer le CSV d'origine. Par exemple, la première colonne du tableau 2D ci-dessus, qui est égale à 0,0,0,0 correspond à haut,gauche,petit,bas: \"haut\" correspondant au 0 de la première variable aléatoire, \"gauche\" correspondant au 0 de la 2ème variable, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lisez-le fichier [tme5_asia.csv](tme5_asia.csv) à l'aide de la fonction read_csv ci-dessous: la dernière instruction, `names, data, dico = read_csv ( \"tme5_asia.csv\" )`, vous permettra de récupérer, séparément, les trois champs du triplet renvoyé par la fonction read_csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['visit_to_Asia?' 'smoking?' 'tuberculosis?' 'lung_cancer?' 'bronchitis?'\n",
      " 'tuberculos_or_cancer?' 'dyspnoea?' 'positive_XraY?']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 1 0 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 0 1 ... 1 0 0]\n",
      " [0 1 1 ... 1 1 1]]\n",
      "[{'true': 0, 'false': 1} {'false': 0, 'true': 1} {'true': 0, 'false': 1}\n",
      " {'false': 0, 'true': 1} {'false': 0, 'true': 1} {'false': 0, 'true': 1}\n",
      " {'false': 0, 'true': 1} {'false': 0, 'true': 1}]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# fonction pour transformer les données brutes en nombres de 0 à n-1\n",
    "def translate_data ( data ):\n",
    "    # création des structures de données à retourner\n",
    "    nb_variables = data.shape[0]\n",
    "    nb_observations = data.shape[1] - 1 # - nom variable\n",
    "    res_data = np.zeros ( (nb_variables, nb_observations ), int )\n",
    "    res_dico = np.empty ( nb_variables, dtype=object )\n",
    "\n",
    "    # pour chaque variable, faire la traduction\n",
    "    for i in range ( nb_variables ):\n",
    "        res_dico[i] = {}\n",
    "        index = 0\n",
    "        for j in range ( 1, nb_observations + 1 ):\n",
    "            # si l'observation n'existe pas dans le dictionnaire, la rajouter\n",
    "            if data[i,j] not in res_dico[i]:\n",
    "                res_dico[i].update ( { data[i,j] : index } )\n",
    "                index += 1\n",
    "            # rajouter la traduction dans le tableau de données à retourner\n",
    "            res_data[i,j-1] = res_dico[i][data[i,j]]\n",
    "    return ( res_data, res_dico )\n",
    "\n",
    "\n",
    "# fonction pour lire les données de la base d'apprentissage\n",
    "def read_csv ( filename ):\n",
    "    data = np.loadtxt ( filename, delimiter=',', dtype=np.str ).T\n",
    "    names = data[:,0].copy ()\n",
    "    data, dico = translate_data ( data )\n",
    "    return names, data, dico\n",
    "\n",
    "# names : tableau contenant les noms des variables aléatoires\n",
    "# data  : tableau 2D contenant les instanciations des variables aléatoires\n",
    "# dico  : tableau de dictionnaires contenant la correspondance (valeur de variable -> nombre)\n",
    "\n",
    "names, data, dico = read_csv ( \"tme5_asia.csv\" )\n",
    "print(names)\n",
    "print(data)\n",
    "print(dico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Statistique du $\\chi^2$ conditionnel\n",
    "\n",
    "\n",
    "Soit deux variables aléatoires $X$ et $Y$. Appelons $N_{xy}$, $N_x$ et $N_y$, respectivement, le nombre d'occurrences du couple $(X=x,Y=y)$ et des singletons $X=x$ et $Y=y$ dans la base de données. Alors, comme indiqué dans le cours 5, la statistique du $\\chi^2$ de $X$ et $Y$ est égale à : \n",
    "\n",
    "\n",
    "$$\\chi^2_{X,Y} = \\sum_x\\sum_y\\frac{\\left(N_{xy} - \\frac{N_x \\times N_y}{N}\\right)^2}{\\frac{N_x \\times N_y}{N}}$$\n",
    "\n",
    "où {$N$} représente le nombre de lignes de la base de données. Cette formule permet de tester l'indépendance entre les deux variables {$X$} et {$Y$}. On peut aisément généraliser celle-ci pour tester des indépendances conditionnellement à un ensemble de variables {$\\mathbf{Z}$}:\n",
    "\n",
    "$$\\chi^2_{X,Y|\\mathbf{Z}} = \\sum_x\\sum_y\\sum_{\\mathbf{z}}\\frac{\\left(N_{xy\\mathbf{z}} - \\frac{N_{x\\mathbf{z}} \\times N_{y\\mathbf{z}}}{N_{\\mathbf{z}}}\\right)^2}{\\frac{N_{x\\mathbf{z}} \\times N_{y\\mathbf{z}}}{N_{\\mathbf{z}}}}$$\n",
    "\n",
    "où $N_{xy\\mathbf{z}}$, $N_{x\\mathbf{z}}$, $N_{y\\mathbf{z}}$ et $N_{\\mathbf{z}}$ représentent, respectivement, le nombre d'occurrences du triplet $(X=x,Y=y,\\mathbf{Z} = \\mathbf{z})$, des couples $(X=x,\\mathbf{Z} = \\mathbf{z})$ et $(Y=y,\\mathbf{Z} = \\mathbf{z})$, et du singleton $\\mathbf{Z} = \\mathbf{z}$. Ainsi, si $\\mathbf{Z}$ est un ensemble de 3 variables aléatoires $(A,B,C)$, les valeurs $\\mathbf{z}$ seront des triplets $(a,b,c)$.\n",
    "\n",
    "Afin de vous aider à calculer ces $\\chi^2$, vous pourrez utiliser la fonction **create_contingency_table** `: int np.2D-array x dico{string -> int} np.array x int x int x int list -> (int, np.2D-array) np.array` ci-dessous. Celle-ci prend en argument le tableau 2D numpy `data` et le tableau de dictionnaires `dico` retournés à la fin de la question 1, ainsi que l'index `x` d'une variable aléatoire (0 = 1ère variable aléatoire (celle de la 1ère ligne de `data`), 1 = 2ème variable, _etc._), l'index `y` d'une autre variable et une liste `z` d'index d'autres variables aléatoires. Elle renvoie un tableau de couples ({$N_{\\mathbf{z}}, T_{X,Y,\\mathbf{z}})$}, pour tous les {$\\mathbf{z} \\in\\mathbf{Z}$}, où:\n",
    "\n",
    "*   $N_{\\mathbf{z}}$ représente le nombre d'occurences de {$Z=z$} dans la base de données. Par exemple, si la base de données est la suivante :\n",
    "\n",
    "```\n",
    " X_0,X_1,X_2,X_3\n",
    " haut,gauche,petit,bas\n",
    " bas,droite,grand,gauche\n",
    " bas,gauche,moyen,bas\n",
    "```\n",
    "\n",
    "nous avons vu plus haut que le tableau data est égal à : \n",
    "\n",
    "```python\n",
    "data = np.array ( [ [0, 1, 1],    # instanciations de la variable X_0\n",
    "                     [0, 1, 0],    # instanciations de la variable X_1\n",
    "                     [0, 1, 2],    # instanciations de la variable X_2\n",
    "                     [0, 1, 0]] )  # instanciations de la variable X_3\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'application de **create_contingency_table ( data, dico, 0, 2, [3] ) **renverra le tableau: \n",
    "```python\n",
    "resultat = array([ (2, array([[ 1.,  0.,  0.],        # Z = 0 => N_{Z=0} = 2\n",
    "                               [ 0.,  0.,  1.]])),\n",
    "                    (1, array([[ 0.,  0.,  0.],        # Z = 1 => N_{Z=1} = 1\n",
    "                               [ 0.,  1.,  0.]])) ])\n",
    "```\n",
    "\n",
    "\n",
    "C'est a dire : \n",
    "Si $X_3=0$\n",
    "\n",
    "|  \t| $X_2$=0| $X_2$=1 \t| $X_2$=3 \t|\n",
    "|:-------:\t|:-------:\t|:-------:\t|:-------:\t|\n",
    "| $X_0$=0 \t|          1 \t| 0 \t| 0 \t|\n",
    "| $X_0$=1 \t|          0 \t| 0 \t| 1 \t|\n",
    "\n",
    "Si $X_3=1$\n",
    "\n",
    "|  \t| $X_2$=0| $X_2$=1 \t| $X_2$=3 \t|\n",
    "|:-------:\t|:-------:\t|:-------:\t|:-------:\t|\n",
    "| $X_0$=0 \t|          0 \t| 0 \t| 0 \t|\n",
    "| $X_0$=1 \t|          0 \t| 1 \t| 0 \t|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En effet le paramètre `[3]` indique que $\\mathbf{Z}$ est constitué uniquement de la quatrième variable de la base, autrement dit $X_3$. La dernière ligne du tableau `data` indique les instanciations de X_3 et l'on peut observer que la valeur 0 apparaît 2 fois et la valeur 1 apparaît une fois. On a donc $N_{Z=0} = 2$ et $N_{Z=1} = 1$. On peut observer que les valeurs de $N_{\\mathbf{Z}}$ sont bien les premiers éléments des couples de `resultat`. Lorsque $\\mathbf{Z} = \\emptyset$, `resultat` est un tableau avec un seul couple dont le premier élément correspond précisément à $N$, le nombre d'enregistrements de la base de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  $T_{X,Y,\\mathbf{z}}$ est un tableau 2D contenant le nombre d'occurrences $N_{xy\\mathbf{z}}$ des couples $(X=x,Y=y)$ lorsque $\\mathbf{Z}=\\mathbf{z}$. La première dimension de ce tableau (les lignes) correspondent aux différentes valeurs de $X$ et la deuxième (les colonnes) à celles de {$Y$}. Ainsi, le tableau en haut à droite de `resultat` est obtenu de la manière suivante: ce tableau correspond à des occurrences de $(X,Y)$ lorsque $\\mathbf{Z}=0$. on commence donc par extraire de `data` le sous-tableau correspondant à la première et à la troisième colonne (les colonnes où X_3=0) et on ne retient que les lignes correspondant à X_0 et X_2 (cf. les paramètres 0 et 2 passés en arguments de **create_contingency_table**). On obtient donc le sous-tableau:\n",
    "\n",
    "```python\n",
    "np.array ( [ [0, 1],    # instanciations de la variable X_0\n",
    "              [0, 2]] )  # instanciations de la variable X_2\n",
    "```\n",
    "\n",
    "Ce tableau nous indique que, lorsque $X_3=0$, les couples $(X_0=0,X_2=0)$ et $(X_0=1,X_2=2)$ apparaissent une seule fois et ce sont les seuls couples qui apparaissent dans la base de données. C'est précisément ce que représente le tableau en haut à droite de `resultat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etant donné une BD data et son dictionnaire, cette fonction crée le\n",
    "# tableau de contingence de (x,y) | z\n",
    "\n",
    "def create_contingency_table ( data, dico, x, y, z ):\n",
    "    # détermination de la taille de z\n",
    "    size_z = 1\n",
    "    offset_z = np.zeros ( len ( z ) )\n",
    "    j = 0\n",
    "    for i in z:\n",
    "        offset_z[j] = size_z      \n",
    "        size_z *= len ( dico[i] )\n",
    "        j += 1\n",
    "\n",
    "    # création du tableau de contingence\n",
    "    res = np.zeros ( size_z, dtype = object )\n",
    "\n",
    "    # remplissage du tableau de contingence\n",
    "    if size_z != 1:\n",
    "        z_values = np.apply_along_axis ( lambda val_z : val_z.dot ( offset_z ),\n",
    "                                         1, data[z,:].T )\n",
    "        i = 0\n",
    "        while i < size_z:\n",
    "            indices, = np.where ( z_values == i )\n",
    "            a,b,c = np.histogram2d ( data[x,indices], data[y,indices],\n",
    "                                     bins = [ len ( dico[x] ), len (dico[y] ) ] )\n",
    "            res[i] = ( indices.size, a )\n",
    "            i += 1\n",
    "    else:\n",
    "        a,b,c = np.histogram2d ( data[x,:], data[y,:],\n",
    "                                 bins = [ len ( dico[x] ), len (dico[y] ) ] )\n",
    "        res[0] = ( data.shape[1], a )\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(103, array([[  0., 102.],\n",
      "       [  0.,   1.]]))\n",
      " (1897, array([[1.842e+03, 2.600e+01],\n",
      "       [2.800e+01, 1.000e+00]]))]\n"
     ]
    }
   ],
   "source": [
    "resultat=create_contingency_table ( data, dico, 0, 2, [3]) \n",
    "print(resultat)\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En utilisant la structure retournée par la fonction **create_contingency_table**, écrivez une fonction **sufficient_statistics**`: int np.2D-array x dico{string -> int} np.array x int x int x int list -> float` qui prend les mêmes arguments que la fonction **create_contingency_table** et qui renvoie la valeur de $\\chi^2_{X,Y|\\mathbf{Z}}$. Vous pourrez tirer profit du fait que $N_{x\\mathbf{z}} = \\sum_{y} N_{xy\\mathbf{z}}$ et $N_{y\\mathbf{z}} = \\sum_{x} N_{xy\\mathbf{z}}$, ce qui revient à faire des sommes sur chaque ligne ou chaque colonne des tableaux $T_{X,Y,\\mathbf{z}}$. \n",
    "\n",
    "**Attention :** il peut arriver que certains $N_{\\mathbf{z}}$ soient égaux à 0\\. Dans ce cas, vous ne tiendrez pas compte des $N_{xy\\mathbf{z}}$, $N_{x\\mathbf{z}}$ et $N_{y\\mathbf{z}}$ correspondants dans la formule de $\\chi^2_{X,Y|\\mathbf{Z}}$ (car vous feriez des divisions par 0, ce qui est mal).\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9466591186668287\n"
     ]
    }
   ],
   "source": [
    "def sufficient_statistics ( data, dico, x, y, z ):\n",
    "    # création du tableau de contingence\n",
    "    table = create_contingency_table ( data, dico, x, y, z )\n",
    "    nb_z = table.shape[0]\n",
    "    nb_x, nb_y = table[0][1].shape\n",
    "    \n",
    "    resultat = 0\n",
    "    for z in range(nb_z):\n",
    "        N_xyz = table[z][1]\n",
    "        N_z = table[z][0]\n",
    "        if(N_z != 0):\n",
    "            N_xz = table[z][1].sum(axis = 1)\n",
    "            N_yz = table[z][1].sum(axis = 0)\n",
    "            for y in range(nb_y):\n",
    "                for x in range(nb_x):\n",
    "                    tmp = (N_xz[x] * N_yz[y])/N_z\n",
    "                    if(tmp != 0):\n",
    "                        resultat += ((N_xyz[x,y] - tmp )**2 )/ tmp\n",
    "                \n",
    "                \n",
    "                \n",
    "    return resultat\n",
    "    \n",
    "print(sufficient_statistics ( data, dico, 1,2,[3]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vous pourrez vérifier la validité de vos calculs: en utilisant la base de données \"2015_tme5_asia.csv\", vous devriez obtenir les résultats suivants :\n",
    "\n",
    "\n",
    "| appel de la fonction \t| résultat \t|\n",
    "|--------------------------------------------------\t|--------------------\t|\n",
    "| sufficient_statistics ( data, dico, 1,2,[3]) \t| 3.9466591186668296 \t|\n",
    "| sufficient_statistics ( data, dico, 0,1,[2,3]) \t| 16.355207462350094 \t|\n",
    "| sufficient_statistics ( data, dico, 1,3,[2]) \t| 81.807449348140295 \t|\n",
    "| sufficient_statistics ( data, dico, 5,2,[1,3,6]) \t| 1897.0 \t|\n",
    "| sufficient_statistics ( data, dico, 0,7,[4,5]) \t| 3.2223237760949699 \t|\n",
    "| sufficient_statistics ( data, dico, 2,3,[5]) \t| 130.0 \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9466591186668287\n"
     ]
    }
   ],
   "source": [
    "print(sufficient_statistics ( data, dico, 1,2,[3]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Statistique du $\\chi^2$ et degré de liberté\n",
    "\n",
    "Modifiez votre fonction **sufficient_statistics** afin qu'elle ne renvoie plus seulement $\\chi^2_{X,Y|\\mathbf{Z}}$ mais plutôt un couple ($\\chi^2_{X,Y|\\mathbf{Z}}$,DoF), où DoF est le nombre de degrés de liberté de votre statistique. Celui-ci est égal à :\n",
    "\n",
    "$$(|X|-1) \\times (|Y|-1) \\times |\\{\\mathbf{z} : N_{\\mathbf{z}} \\neq 0\\}| $$\n",
    "\n",
    "où $|X|$ représente le nombre de valeurs possibles que peut prendre la variable $X$, autrement dit, c'est la taille de son dictionnaire. Le dernier terme de l'équation est simplement le nombre de $N_{\\mathbf{z}}$ différents de 0.\n",
    "\n",
    "Vous pourrez vérifier la validité de vos calculs: en utilisant la base de données \"2015_tme5_asia.csv\", vous devriez obtenir les résultats suivants:\n",
    "\n",
    "| appel de la fonction \t| résultat \t|\n",
    "|:------------------------------------------------:\t|:-----------------------:\t|\n",
    "| sufficient_statistics ( data, dico, 1,2,[3]) \t| (3.9466591186668296, 2) \t|\n",
    "| sufficient_statistics ( data, dico, 0,1,[2,3]) \t| (16.355207462350094, 3) \t|\n",
    "| sufficient_statistics ( data, dico, 1,3,[2]) \t| (81.807449348140295, 2) \t|\n",
    "| sufficient_statistics ( data, dico, 5,2,[1,3,6]) \t| (1897.0, 8) \t|\n",
    "| sufficient_statistics ( data, dico, 0,7,[4,5]) \t| (3.2223237760949699, 4) \t|\n",
    "| sufficient_statistics ( data, dico, 2,3,[5]) \t| (130.0, 2) \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16.35520746235009, 3)\n"
     ]
    }
   ],
   "source": [
    "def sufficient_statistics(  data, dico, x, y, z  ):\n",
    "    table = create_contingency_table ( data, dico, x, y, z )\n",
    "    nb_z = table.shape[0]\n",
    "    nb_x, nb_y = table[0][1].shape\n",
    "    \n",
    "    NzNoZero = 0\n",
    "    resultat = 0\n",
    "    for z in range(nb_z):\n",
    "        N_xyz = table[z][1]\n",
    "        N_z = table[z][0]\n",
    "        if(N_z != 0):\n",
    "            NzNoZero += 1\n",
    "            N_xz = table[z][1].sum(axis = 1)\n",
    "            N_yz = table[z][1].sum(axis = 0)\n",
    "            for y in range(nb_y):\n",
    "                for x in range(nb_x):\n",
    "                    tmp = (N_xz[x] * N_yz[y])/N_z\n",
    "                    if(tmp != 0):\n",
    "                        resultat += ((N_xyz[x,y] - tmp )**2 )/ tmp\n",
    "                \n",
    "                \n",
    "    return resultat , ((nb_x - 1) * (nb_y - 1)  * NzNoZero )\n",
    "\n",
    "\n",
    "print(sufficient_statistics ( data, dico, 0,1,[2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test d'indépendance\n",
    "\n",
    "En cours, nous avons vu que, pour un risque $\\alpha$ donné, si la statistique $\\chi^2_{X,Y|\\mathbf{Z}}$ est inférieure au seuil critique $c_{\\alpha}$ de la loi du $\\chi^2$ à DoF degrés de liberté, alors $X$ et $Y$ sont considérés comme indépendants conditionnellement à $\\mathbf{Z}$ ($X \\perp\\hspace{-1.7mm}\\perp Y | \\mathbf{Z}$). On peut reformuler cette propriété de la manière suivante :\n",
    "\n",
    "$$\\text{p-value}(\\chi^2_{X,Y|\\mathbf{Z}}) \\geq \\alpha \\Longleftrightarrow X \\perp\\hspace{-1.7mm}\\perp Y | \\mathbf{Z}$$\n",
    "\n",
    "La p-value d'un nombre x est l'intégrale de la fonction de densité de la loi du $\\chi^2$ de x à $+\\infty$ (autrement dit, c'est la surface de la partie grisée sur votre table du $\\chi^2$ à partir de l'abscisse x. On a donc p-value$(c_{\\alpha}) = \\alpha$. En statistiques, on considère qu'elle n'a du sens que si les valeurs du tableau de contingence sont toutes supérieures ou égales à 5 (autrement dit, un test d'indépendance du $\\chi^2$ n'est \"valide\" que si toutes les valeurs du tableau de contingence sont supérieures ou égales à 5). En informatique, on allège souvent cette règle en considérant que le test est valide dès lors que la valeur moyenne des cases est supérieure ou égale à 5\\. Cet allègement permet de tester la validité du test sans réaliser celui-ci : si le nombre de lignes du CSV est supérieure ou égale à $d_{min} = 5 \\times |X| \\times |Y| \\times |\\mathbf{Z}|$, le test est considéré comme valide.\n",
    "\n",
    "Ecrivez une fonction **indep_score** `: int np.2D-array x dico{string -> int} np.array x int x int x int list -> (float,int)` qui, étant donné les mêmes paramètres que ceux de la question précédente, vous renvoie un couple contenant la p-value correspondant à $\\chi^2_{X,Y|\\mathbf{Z}}$ ainsi que le nombre de degrés de liberté de cette statistique. Vous testerez au préalable si len ( data[0] ), le nombre de lignes/enregistrements de votre CSV, est supérieur ou non à $d_{min}$; si c'est inférieur, vous renverrez le couple (-1,1), qui représente une indépendance. Vous pourrez vous aider de la fonction scipy.stats.chi2.sf ( x, DoF ) qui renvoie la p-value (x) pour une loi à DoF degrés de liberté.\n",
    "\n",
    "``` python\n",
    "import scipy.stats as stats\n",
    "stats.chi2.sf ( x, DoF )\n",
    "```\n",
    "\n",
    "\n",
    "Vous pourrez vérifier la validité de vos calculs: en utilisant la base de données \"2015_tme5_asia.csv\", vous devriez obtenir les résultats suivants:\n",
    "\n",
    "| appel de la fonction \t| résultat \t|\n",
    "|:----------------------------------------------:\t|:-----------------:\t|\n",
    "| indep_score ( data, dico, 1,3,[]) \t| 2.38520176938e-19 \t|\n",
    "| indep = indep_score ( data, dico, 1, 7, []) \t| 1.12562784979e-10 \t|\n",
    "| indep = indep_score ( data, dico, 0, 1,[2, 3]) \t| 0.000958828236575 \t|\n",
    "| indep = indep_score ( data, dico, 1, 2,[3, 4]) \t| 0.475266197894 \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fonction qui renvoie la p-value du test: x indépendant de y | z\n",
    "def indep_score ( data, dico, x, y, z ):\n",
    "    ## votre code\n",
    "    pass\n",
    "\n",
    "\n",
    "## indep_score ( data, dico, 1,3,[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Meilleur candidat pour être un parent (Partie optionnelle)\n",
    "\n",
    "Ecrivez une fonction **best_candidate** `: int np.2D-array x dico{string -> int} np.array x int x int list x float -> int list` qui, étant donné les tableaux `data` et `dico` calculés à la question 1, l'index d'une variable aléatoire $X$, la liste d'index d'un ensemble de variables aléatoires $\\mathbf{Z}$ et un risque $\\alpha$, détermine la variable $Y$ (en fait, l'index de sa colonne dans le CSV), parmi toutes celles à gauche de $X$ dans le fichier CSV, qui est la plus dépendante de $X$ conditionnellement à $\\mathbf{Z}$, autrement dit, celle qui a la plus petite p-value. Si cette p-value est supérieure à $\\alpha$, cela veut dire que $\\chi^2_{X,Y|\\mathbf{Z}}$ est inférieur à $c_{\\alpha}$ et donc que $Y$ est jugée indépendante de $X$ conditionnellement à $\\mathbf{Z}$. \n",
    "\n",
    "Votre fonction renverra une liste vide si $Y$ est indépendante de $X$ conditionnellement à $\\mathbf{Z}$, sinon elle renverra une liste contenant $Y$. Vous pourrez tester votre fonction avec $\\alpha$ = 0.05:\n",
    "\n",
    "| appel de la fonction \t| résultat \t|\n",
    "|-----------------------------------------------\t|----------\t|\n",
    "| best_candidate ( data, dico, 1, [], 0.05 ) \t| [] \t|\n",
    "| best_candidate ( data, dico, 4, [], 0.05 ) \t| [1] \t|\n",
    "| best_candidate ( data, dico, 4, [1], 0.05 ) \t| [] \t|\n",
    "| best_candidate ( data, dico, 5, [], 0.05 ) \t| [3] \t|\n",
    "| best_candidate ( data, dico, 5, [6], 0.05 ) \t| [3] \t|\n",
    "| best_candidate ( data, dico, 5, [6,7], 0.05 ) \t| [2] \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fonction qui, étant donné un couple (x,z), renvoie une liste vide si tous\n",
    "# les y !=x,z sont indépendants de x conditionnellement à z, ou bien une\n",
    "# liste contenant le meilleur y (celui avec la p-value la plus petite) s'il\n",
    "# existe des y dont la p-value est inférieur au seuil\n",
    "def best_candidate ( data, dico, x, z, risk_level ):\n",
    "    ## votre code\n",
    "    pass\n",
    "\n",
    "\n",
    "#best_candidate ( data, dico, 1, [], 0.05 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Création des parents d'un noeud (Partie optionnelle)\n",
    "Ecrivez une fonction **create_parents** ( data, dico, x, alpha ) qui, étant donné une variable aléatoire x et un niveau de risque alpha, retourne la liste z de ses parents dans le réseau bayésien. L'algorithme est le suivant : partez de z = l'ensemble vide, puis tant que **best_candidate** ( x, z, alpha ) vous renvoie une liste non vide [y], rajoutez y à z. Lorsque vous sortirez de cette boucle, toutes les autres variables seront indépendantes de x conditionnellement à z.\n",
    "\n",
    "L'algorithme qui consiste à appliquer, pour chaque noeud/variable aléatoire, votre fonction **create_parents** correspond, en grande partie, à l'article suivant :\n",
    "\n",
    "Gregory F. Cooper and Edward Herskovits (1992) \"A Bayesian method for the induction of probabilistic networks from data\", _Machine Learning_, Vol. 9, n°4, pp. 309-347.  \n",
    "\n",
    "Vous pourrez tester la validité de votre fonction :\n",
    "\n",
    "| appel de la fonction \t| résultat \t|\n",
    "|----------------------------------------\t|----------\t|\n",
    "| create_parents ( data, dico, 1, 0.05 ) \t| [] \t|\n",
    "| create_parents ( data, dico, 4, 0.05 ) \t| [1] \t|\n",
    "| create_parents ( data, dico, 5, 0.05 ) \t| [3, 2] \t|\n",
    "| create_parents ( data, dico, 6, 0.05 ) \t| [4, 5] \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pour un noeud donné, crée la liste de ses parents\n",
    "def create_parents ( data, dico, x, risk_level ):\n",
    "    ## votre code\n",
    "    pass\n",
    "\n",
    "\n",
    "#create_parents ( data, dico, 1, 0.05 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Apprentissage de la structure d'un réseau bayésien (Partie optionnelle)\n",
    "\n",
    "Ecrivez une fonction **learn_BN_structure** ( data, dico, alpha ) qui renvoie un tableau contenant, pour chaque noeud, la liste de ses parents. Ainsi, si votre fonction vous renvoie le tableau ci-dessous,\n",
    "```python\n",
    " array( [ [], [], [], [1, 0], [1], [3, 2], [4, 5], [5] ] )\n",
    "```\n",
    "\n",
    "les noeud correspondant aux 2 premières colonnes du CSV n'ont pas de parents, le noeud de la 3ème colonne a pour parent celui de la 1ère colonne, etc.\n",
    "\n",
    "Pour visualiser plus aisément votre structure, utilisez la fonction **display_BN** ci-dessous. Celle-ci prend en paramètres :\n",
    "\n",
    "1.  le tableau des noms des variables aléatoires déterminé à la question 1\n",
    "2.  la structure que vous avez calculée avec votre fonction **learn_BN_structure**\n",
    "3.  un nom que vous voulez donner à votre réseau\n",
    "4.  un style pour afficher les noeuds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apprentissage de la structure d'un réseau bayésien par K2\n",
    "def learn_BN_structure ( data, dico, risk_level ):\n",
    "    ## votre code\n",
    "    pass\n",
    "\n",
    "bn_struct = learn_BN_structure ( data, dico, 0.05 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pydotplus\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "style = { \"bgcolor\" : \"#6b85d1\", \"fgcolor\" : \"#FFFFFF\" }\n",
    "\n",
    "def display_BN ( node_names, bn_struct, bn_name, style ):\n",
    "    graph = pydot.Dot( bn_name, graph_type='digraph')\n",
    "\n",
    "    # création des noeuds du réseau\n",
    "    for name in node_names:\n",
    "        new_node = pydot.Node( name,\n",
    "                               style=\"filled\",\n",
    "                               fillcolor=style[\"bgcolor\"],\n",
    "                               fontcolor=style[\"fgcolor\"] )\n",
    "        graph.add_node( new_node )\n",
    "\n",
    "    # création des arcs\n",
    "    for node in range ( len ( node_names ) ):\n",
    "        parents = bn_struct[node]\n",
    "        for par in parents:\n",
    "            new_edge = pydot.Edge ( node_names[par], node_names[node] )\n",
    "            graph.add_edge ( new_edge )\n",
    "\n",
    "    # sauvegarde et affaichage\n",
    "    outfile = bn_name + '.png'\n",
    "    graph.write_png( outfile )\n",
    "    img = mpimg.imread ( outfile )\n",
    "    plt.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display_BN ( names, bn_struct, \"asia\", style )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fin de l'apprentissage et calcul probabiliste (Partie optionnelle)\n",
    "\n",
    "Comme précisé au début du TME, apprendre un réseau bayésien consiste à déterminer sa structure graphique et estimer ses paramètres. Vous avez réalisé la première partie. La deuxième, plus simple, peut se faire par maximum de vraisemblance pour chaque table de probabilité des noeuds conditionnellement à leurs parents, comme dans le TME 3\\. Utilisez la fonction **learn_parameters** ci-dessous pour effectuer cette tâche. Cette fonction prend en paramètres la structure graphique que vous avez apprise ainsi que le nom du fichier CSV que vous avez utilisé pour votre apprentissage. Elle renvoie un réseau bayésien à la [aGrUM](http://agrum.org). Pour pouvoir utiliser aGrUM, reportez-vous à la [question 7 du TME 2].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyAgrum as gum\n",
    "import pyAgrum.lib.ipython as gnb\n",
    "\n",
    "\n",
    "def learn_parameters ( bn_struct, ficname ):\n",
    "    # création du dag correspondant au bn_struct\n",
    "    graphe = gum.DAG ()\n",
    "    nodes = [ graphe.addNode () for i in range ( bn_struct.shape[0] ) ]\n",
    "    for i in range ( bn_struct.shape[0] ):\n",
    "        for parent in bn_struct[i]:\n",
    "            graphe.addArc ( nodes[parent], nodes[i] )\n",
    "\n",
    "    # appel au BNLearner pour apprendre les paramètres\n",
    "    learner = gum.BNLearner ( ficname )\n",
    "    learner.useScoreLog2Likelihood ()\n",
    "    learner.useAprioriSmoothing ()\n",
    "    return learner.learnParameters ( graphe )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vous pouvez maintenant réaliser des calculs probabilistes :\n",
    "\n",
    "- affichage de la taille du réseau bayésien\n",
    "\n",
    "```python\n",
    "# création du réseau bayésien à la aGrUM\n",
    "bn = learn_parameters ( bn_struct, ficname )\n",
    "\n",
    "# affichage de sa taille\n",
    "print(bn)\n",
    "```\n",
    "\n",
    "- affichage de la table de probabilité conditionnelle d'un noeud du réseau déterminé par son nom (1ère ligne du CSV):\n",
    "\n",
    "```python\n",
    "\n",
    "# récupération de la ''conditional probability table'' (CPT) et affichage de cette table\n",
    "gnb.showPotential( bn.cpt ( bn.idFromName ( 'bronchitis?' ) ) )\n",
    "```\n",
    "\n",
    "- calcul de la probabilité marginale d'un noeud : P('bronchitis?'):\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "# calcul de la marginale\n",
    "proba = gum.getPosterior ( bn, {}, 'bronchitis?' )\n",
    "\n",
    "```\n",
    "\n",
    "- affichage graphique d'une distribution de probabilité marginale\n",
    "\n",
    "```python\n",
    "# affichage de la marginale\n",
    "gnb.showPotential( proba )\n",
    "\n",
    "```\n",
    "- calcul d'une distribution marginale a posteriori : P(bronchitis? | smoking? = true, turberculosis? = false )\n",
    "```python\n",
    "gnb.showPotential(gum.getPosterior ( bn,{'smoking?': 'true', 'tuberculosis?' : 'false' }, 'bronchitis?' ))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. (Bonus) Autres bases de données\n",
    "\n",
    "Vous pouvez appliquer vos algorithmes sur des bases un peu plus conséquentes qu'asia:\n",
    "\n",
    "|  nom de la base  |            provenance           | nombre d'evenements elementaires |\n",
    "|:----------------:|:-------------------------------:|:--------------------------------:|\n",
    "|       asia       |          BN repository          |                $256     $          |\n",
    "|       alarm      |          BN repository          |              $10^{16}   $               |\n",
    "|       adult      | UCI machine learning repository |              $10^{12}   $          |\n",
    "|        car       | UCI machine learning repository |               $6912     $          |\n",
    "| agaricus-lepiota | UCI machine learning repository |              $10^{16}   $        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
